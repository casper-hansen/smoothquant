{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from smoothquant.smooth import smooth_lm\n",
    "from smoothquant.utils import Perplexity\n",
    "from smoothquant.opt import Int8OPTForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from smoothquant.calibration import get_act_scales, get_static_decoder_layer_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'facebook/opt-6.7b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP16 Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fed57d490f4e15a582dce1a44d43d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_fp16 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcabf5d910a4196b3c174d02f85507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Perplexity: - :   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     ppl \u001b[39m=\u001b[39m Perplexity(model_fp16, tokenizer)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     out \u001b[39m=\u001b[39m ppl\u001b[39m.\u001b[39;49mcalculate_perplexity()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFP16 perplexity: \u001b[39m\u001b[39m{\u001b[39;00mout[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/utils.py:73\u001b[0m, in \u001b[0;36mPerplexity.calculate_perplexity\u001b[0;34m(self, n_ctx, n_batch, tokens)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tokens[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_ctx), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPerplexity: - \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m progress:\n\u001b[1;32m     72\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m progress:\n\u001b[0;32m---> 73\u001b[0m         nll, count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_batch(i, n_ctx, n_batch, tokens, nll, count)\n\u001b[1;32m     74\u001b[0m         curr_ppl \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(nll \u001b[39m/\u001b[39m count)\n\u001b[1;32m     75\u001b[0m         all_perplexity\u001b[39m.\u001b[39mappend(curr_ppl)\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/utils.py:100\u001b[0m, in \u001b[0;36mPerplexity._process_batch\u001b[0;34m(self, i, n_ctx, n_batch, tokens, nll, count)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mmin\u001b[39m(\u001b[39m512\u001b[39m, n_ctx \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m), n_ctx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     99\u001b[0m     tok_logits \u001b[39m=\u001b[39m logits[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][j]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m--> 100\u001b[0m     prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(tok_logits)[tokens[\u001b[39m0\u001b[39m][start \u001b[39m+\u001b[39m j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]]\n\u001b[1;32m    101\u001b[0m     nll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mlog(prob, where\u001b[39m=\u001b[39mprob\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    102\u001b[0m     count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/utils.py:58\u001b[0m, in \u001b[0;36mPerplexity.softmax\u001b[0;34m(logits)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msoftmax\u001b[39m(logits):\n\u001b[0;32m---> 58\u001b[0m     e_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mexp(logits \u001b[39m-\u001b[39;49m np\u001b[39m.\u001b[39;49mmax(logits))\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m e_x \u001b[39m/\u001b[39m e_x\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppl = Perplexity(model_fp16, tokenizer)\n",
    "out = ppl.calculate_perplexity()\n",
    "print(f'FP16 perplexity: {out[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmoothQuant W8A8 Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d8dcd02627458f9cf82d6b74a1a8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "100%|██████████| 512/512 [00:47<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting activation scales...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/512 [00:00<?, ?it/s]Repo card metadata block was not found. Setting CardData to empty.\n",
      "Mean input scale: 5.61: 100%|██████████| 512/512 [00:48<00:00, 10.51it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Char",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m decoder_layer_scales, raw_scales \u001b[39m=\u001b[39m get_static_decoder_layer_scales(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     model,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     tokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     seq_len\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/smoothquant/examples/smoothquant_opt_demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     model_smoothquant_w8a8 \u001b[39m=\u001b[39m Int8OPTForCausalLM\u001b[39m.\u001b[39;49mfrom_float(model, decoder_layer_scales)\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/opt.py:437\u001b[0m, in \u001b[0;36mInt8OPTForCausalLM.from_float\u001b[0;34m(module, decoder_layer_scales)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    435\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_float\u001b[39m(module, decoder_layer_scales):\n\u001b[1;32m    436\u001b[0m     int8_module \u001b[39m=\u001b[39m Int8OPTForCausalLM(module\u001b[39m.\u001b[39mconfig)\n\u001b[0;32m--> 437\u001b[0m     int8_module\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m Int8OPTModel\u001b[39m.\u001b[39;49mfrom_float(\n\u001b[1;32m    438\u001b[0m         module\u001b[39m.\u001b[39;49mmodel, decoder_layer_scales)\n\u001b[1;32m    439\u001b[0m     int8_module\u001b[39m.\u001b[39mlm_head \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mlm_head\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m int8_module\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/opt.py:415\u001b[0m, in \u001b[0;36mInt8OPTModel.from_float\u001b[0;34m(module, decoder_layer_scales)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_float\u001b[39m(module, decoder_layer_scales):\n\u001b[1;32m    414\u001b[0m     int8_module \u001b[39m=\u001b[39m Int8OPTModel(module\u001b[39m.\u001b[39mconfig)\n\u001b[0;32m--> 415\u001b[0m     int8_module\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m Int8OPTDecoder\u001b[39m.\u001b[39;49mfrom_float(\n\u001b[1;32m    416\u001b[0m         module\u001b[39m.\u001b[39;49mdecoder, decoder_layer_scales)\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m int8_module\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/opt.py:359\u001b[0m, in \u001b[0;36mInt8OPTDecoder.from_float\u001b[0;34m(module, decoder_layer_scales)\u001b[0m\n\u001b[1;32m    357\u001b[0m int8_module\u001b[39m.\u001b[39mfinal_layer_norm \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mfinal_layer_norm\n\u001b[1;32m    358\u001b[0m \u001b[39mfor\u001b[39;00m i, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(module\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m--> 359\u001b[0m     int8_module\u001b[39m.\u001b[39mlayers[i] \u001b[39m=\u001b[39m Int8OPTDecoderLayer\u001b[39m.\u001b[39;49mfrom_float(\n\u001b[1;32m    360\u001b[0m         layer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdecoder_layer_scales[i])\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m int8_module\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/opt.py:234\u001b[0m, in \u001b[0;36mInt8OPTDecoderLayer.from_float\u001b[0;34m(module, attn_input_scale, q_output_scale, k_output_scale, v_output_scale, out_input_scale, fc1_input_scale, fc2_input_scale)\u001b[0m\n\u001b[1;32m    227\u001b[0m int8_module \u001b[39m=\u001b[39m Int8OPTDecoderLayer(\n\u001b[1;32m    228\u001b[0m     module\u001b[39m.\u001b[39membed_dim,\n\u001b[1;32m    229\u001b[0m     module\u001b[39m.\u001b[39mself_attn\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m    230\u001b[0m     module\u001b[39m.\u001b[39mfc1\u001b[39m.\u001b[39mout_features\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m int8_module\u001b[39m.\u001b[39mself_attn_layer_norm \u001b[39m=\u001b[39m LayerNormQ\u001b[39m.\u001b[39mfrom_float(\n\u001b[1;32m    233\u001b[0m     module\u001b[39m.\u001b[39mself_attn_layer_norm, attn_input_scale)\n\u001b[0;32m--> 234\u001b[0m int8_module\u001b[39m.\u001b[39mself_attn \u001b[39m=\u001b[39m Int8OPTAttention\u001b[39m.\u001b[39;49mfrom_float(\n\u001b[1;32m    235\u001b[0m     module\u001b[39m.\u001b[39;49mself_attn, attn_input_scale, q_output_scale, k_output_scale, v_output_scale, out_input_scale)\n\u001b[1;32m    236\u001b[0m int8_module\u001b[39m.\u001b[39mfinal_layer_norm \u001b[39m=\u001b[39m LayerNormQ\u001b[39m.\u001b[39mfrom_float(\n\u001b[1;32m    237\u001b[0m     module\u001b[39m.\u001b[39mfinal_layer_norm, fc1_input_scale)\n\u001b[1;32m    238\u001b[0m int8_module\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m W8A8B8O8LinearReLU\u001b[39m.\u001b[39mfrom_float(\n\u001b[1;32m    239\u001b[0m     module\u001b[39m.\u001b[39mfc1, fc1_input_scale, fc2_input_scale)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/smoothquant/smoothquant/opt.py:64\u001b[0m, in \u001b[0;36mInt8OPTAttention.from_float\u001b[0;34m(module, input_scale, q_output_scale, k_output_scale, v_output_scale, out_input_scale)\u001b[0m\n\u001b[1;32m     62\u001b[0m module\u001b[39m.\u001b[39mq_proj\u001b[39m.\u001b[39mweight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mscaling\n\u001b[1;32m     63\u001b[0m module\u001b[39m.\u001b[39mq_proj\u001b[39m.\u001b[39mbias \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mscaling\n\u001b[0;32m---> 64\u001b[0m int8_module\u001b[39m.\u001b[39mq_proj \u001b[39m=\u001b[39m W8A8B8O8Linear\u001b[39m.\u001b[39;49mfrom_float(\n\u001b[1;32m     65\u001b[0m     module\u001b[39m.\u001b[39;49mq_proj, input_scale, q_output_scale)\n\u001b[1;32m     66\u001b[0m int8_module\u001b[39m.\u001b[39mk_proj \u001b[39m=\u001b[39m W8A8B8O8Linear\u001b[39m.\u001b[39mfrom_float(\n\u001b[1;32m     67\u001b[0m     module\u001b[39m.\u001b[39mk_proj, input_scale, k_output_scale)\n\u001b[1;32m     68\u001b[0m int8_module\u001b[39m.\u001b[39mv_proj \u001b[39m=\u001b[39m W8A8B8O8Linear\u001b[39m.\u001b[39mfrom_float(\n\u001b[1;32m     69\u001b[0m     module\u001b[39m.\u001b[39mv_proj, input_scale, v_output_scale)\n",
      "File \u001b[0;32m/workspace/smoothquant/torch-int/torch_int/nn/linear.py:50\u001b[0m, in \u001b[0;36mW8A8B8O8Linear.from_float\u001b[0;34m(module, input_scale, output_scale)\u001b[0m\n\u001b[1;32m     48\u001b[0m int8_weight, weight_scale \u001b[39m=\u001b[39m quantize_per_tensor_absmax(module\u001b[39m.\u001b[39mweight)\n\u001b[1;32m     49\u001b[0m mockbias \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, module\u001b[39m.\u001b[39mout_features), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint8, requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 50\u001b[0m int8_bias, bias_scale \u001b[39m=\u001b[39m quantize_per_tensor_absmax(mockbias)\n\u001b[1;32m     51\u001b[0m alpha \u001b[39m=\u001b[39m input_scale \u001b[39m*\u001b[39m weight_scale \u001b[39m/\u001b[39m output_scale\n\u001b[1;32m     52\u001b[0m beta \u001b[39m=\u001b[39m bias_scale \u001b[39m/\u001b[39m output_scale\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/smoothquant/torch-int/torch_int/functional/quantization.py:12\u001b[0m, in \u001b[0;36mquantize_per_tensor_absmax\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     10\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     11\u001b[0m \u001b[39m# use inplace operation to save memory\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m t\u001b[39m.\u001b[39;49mdiv_(scale)\u001b[39m.\u001b[39mround_()\n\u001b[1;32m     13\u001b[0m t_q \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mint8)\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m t_q, scale\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Char"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map='auto',\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# smooth layers\n",
    "act_scales = get_act_scales(model, tokenizer, 'mit-han-lab/pile-val-backup', 512, 512)\n",
    "smooth_lm(model, act_scales, 0.5)\n",
    "\n",
    "# get model scales\n",
    "decoder_layer_scales, raw_scales = get_static_decoder_layer_scales(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    'mit-han-lab/pile-val-backup',\n",
    "    num_samples=512,\n",
    "    seq_len=512\n",
    ")\n",
    "\n",
    "with torch.device(\"cuda\"):\n",
    "    model_smoothquant_w8a8 = Int8OPTForCausalLM.from_float(model, decoder_layer_scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1486c270fecc455d9a76a5404df98a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Perplexity: - :   0%|          | 0/655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmoothQuant W8A8 perplexity: 82762.64201220016\n"
     ]
    }
   ],
   "source": [
    "ppl = Perplexity(model_smoothquant_w8a8, tokenizer)\n",
    "out = ppl.calculate_perplexity()\n",
    "print(f'SmoothQuant W8A8 perplexity: {out[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c458cb81aeeb610631c72e4cc4799f00f630d4dfa7a554b37f8134a7fe160cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
